\section*{Diffusion Models}
\textbf{Noising:} $q(x_t | x_{t-1}) = \mathcal{N}(x_t ; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)$, $\beta_t \in (0,1)$\\%$q(x_{1:T}|x_0) = \prod_{t=1}^T q(x_t | x_{t-1})$
\textbf{Shortcut Noising:} $q(x_t | x_0) = \mathcal{N}(x_t ; \sqrt{\bar \alpha_t} x_0, (1-\bar \alpha_t) I)$ where $\alpha_t = 1-\beta_t \in (0,1)$ and $\bar \alpha_t = \prod_{i=1}^t \alpha_i$ \textcolor{gray}{(proof by induction)}\\
\textbf{Convergence of Noising:} $\lim_{t\to\infty} q(x_t | x_0) = \mathcal{N}(\ \cdot\ ;0, I)$\\

\textbf{Denoising:} $q(x_{t-1} | x_t) = q(x_t | x_{t-1})\frac{q(x_{t-1})}{q(x_t)}$ is intractable, but Gaussian for $\beta_t \approx 0$, hence parametrize $p_\theta(x_{t-1} | x_t)$.

\textbf{Variational Lower Bound of Likelihood:}\\
$\log p_\theta (x_0) \geq \log p_\theta (x_0) - D_{KL}(q(x_{1:T}|x_0)|| p_\theta(x_{1:T} | x_0)) \!=\! $

\resizebox{\linewidth}{!}{$\text{-} \mathbb{E}_{q(x_{1:T}|x_0)} [\log \frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}] \!=\! \text{-} \mathbb{E}_{q(x_{1:T}|x_0)}[\underset{L_T}{D(q(x_T | x_0) || p_\theta(x_T))}$}

\hfill $+\sum_{t=2}^T \underset{L_{t-1}}{D(q(x_{t-1} | x_t, x_0) || p_\theta(x_{t-1} | x_t))} \underset{L_0}{- \log p_\theta(x_0 | x_1)} ]$

\textbf{Diffusion Loss Terms (minimized in $\mathbb{E}_{p(x_0)}\mathbb{E}_{q(x_{1:T}|x_0)}$):}

\resizebox{\linewidth}{!}{$\lim_{T\to\infty} L_T \!=\! D_{KL}(\mathcal{N}(\ \cdot\ ;0,I) || p_\theta(x_T)) \Rightarrow$ set $p_\theta(x_T) = \mathcal{N}(\cdot; 0, I)$.}\\
$L_0$ is often ignored in practice. That leaves $L_t$, where\\

$q(x_{t-1}|x_t, x_0) = \frac{q(x_0 | x_{t-1}) \cdot q(x_{t-1} |x_t)}{q(x_0 | x_t)} \approx \mathcal{N}(x_{t-1}; \tilde \mu(x_t, x_0), \tilde \beta_t I)$ \resizebox{\linewidth}{!}{with $\tilde{\mu}_t(x_t, x_0) = \frac{1}{\sqrt \alpha_t}(x_t - \frac{1-\alpha_t}{\sqrt{1-\bar\alpha_t}} \overset{= \epsilon_t}{\frac{x_t - \sqrt{\bar\alpha_t} x_0}{\sqrt{1-\bar\alpha_t}}})$, $\tilde \beta_t = \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t} \beta_t$.}

\textbf{Parametrization:} $p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_{\theta}(x_t, t), \tilde{\beta}_t I)$\\ 
where $\mu_\theta(x_t, t) = \frac{1}{\sqrt{\alpha_t}} (x_t - \frac{1-\alpha_t}{\sqrt{1-\bar \alpha_t}} \epsilon_\theta(x_t, t))$.

\textbf{Reparametrized Loss:}
$L_t = D_{KL}(q(x_{t-1} | x_t, x_0)||p_\theta(x_{t-1}|x_t))\\ = \frac{||\tilde \mu(x_t, x_0) - \mu_\theta(x_t, t)||^2}{2 \tilde \beta_t} %= \frac{(1-\alpha_t)^2 ||\tfrac{x_t - \sqrt{\bar\alpha_t}x_0}{\sqrt{1-\bar\alpha_t}} - \epsilon_\theta(x_t, t)||^2}{2 \alpha_t (1-\bar \alpha_t) \tilde\beta_t} 
= \frac{(1-\alpha_t)^2 ||\epsilon_t - \epsilon_\theta(\sqrt{\bar\alpha_t}x_0 + \sqrt{1-\bar\alpha_t}\epsilon_t, t)||^2}{2 \alpha_t (1-\bar \alpha_t) \tilde\beta_t}$

\textbf{In practice}, a simplified $L_{VLB}$ is minimized (SGD): $\mathbb{E}_{x_0 \sim p, t \sim \mathcal{U}([1,T]), \epsilon_t \sim \mathcal{N}(0, I)}[||\epsilon_t - \epsilon_\theta(\sqrt{\bar\alpha_t}x_0 + \sqrt{1-\bar\alpha_t}\epsilon_t, t)||_2^2$

\textbf{Generation:} Use $x_T \sim \mathcal{N}(0, I)$ and $x_{t-1} | x_t \sim p_\theta(x_{t-1} | x_t)$.

\textbf{Scheduler:} vital for performance. Slowly decrease $\bar \alpha_t$.

